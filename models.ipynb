{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "93O4_JgNrhkD",
        "Nune_PV1UY2X",
        "2VHFFR9jUg5v",
        "JAWXgov1bawb",
        "QoFixXwrWIKe"
      ],
      "mount_file_id": "1qTihvJOZ1OjSCoGegnAlvrQUYrnX08W7",
      "authorship_tag": "ABX9TyO3pnKWJBH23l76vrx24kCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicole-malaquias/property_price_analysis/blob/main/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling"
      ],
      "metadata": {
        "id": "Z9JHzl3NUspE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importes"
      ],
      "metadata": {
        "id": "AwLt2ONGUyKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "251uigwWNZfO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import  mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.tree import DecisionTreeRegressor # remover no final\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caminho = '/content/drive/MyDrive/Colab Notebooks/desafio/teste_indicium_precificacao.csv'\n",
        "df = pd.read_csv(caminho)\n",
        "\n",
        "caminho_turismo = '/content/drive/MyDrive/Colab Notebooks/desafio/New_York_Tourist_Locations.xlsx'\n",
        "df_t = pd.read_excel(caminho_turismo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vz3ayeWU1-o",
        "outputId": "57273c4f-5f33-49ad-a15b-34a18353a1ba"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padronizando nome das variáveis"
      ],
      "metadata": {
        "id": "Abn5dr7uT4E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rename_columns(df: pd.DataFrame, mapping: dict) -> None:\n",
        "    \"\"\"\n",
        "    Renomeia as colunas de um DataFrame conforme o mapeamento fornecido.\n",
        "\n",
        "    Parâmetros:\n",
        "        df (pd.DataFrame): DataFrame que contém as colunas a serem renomeadas.\n",
        "        mapping (dict): Um dicionário onde as chaves são os nomes atuais das colunas e os valores são os novos nomes das colunas.\n",
        "\n",
        "    Retorna:\n",
        "        None: A função modifica o DataFrame fornecido inplace e não retorna nada.\n",
        "\n",
        "    \"\"\"\n",
        "    df.rename(columns=mapping, inplace=True)\n",
        "\n",
        "mapping = {\n",
        "    'id': 'id',\n",
        "    'nome': 'name',\n",
        "    'host_id': 'host_id',\n",
        "    'host_name': 'host_name',\n",
        "    'bairro_group': 'neighborhood_group',\n",
        "    'bairro': 'neighborhood',\n",
        "    'latitude': 'latitude',\n",
        "    'longitude': 'longitude',\n",
        "    'room_type': 'room_type',\n",
        "    'price': 'price',\n",
        "    'minimo_noites': 'minimum_nights',\n",
        "    'numero_de_reviews': 'number_of_reviews',\n",
        "    'ultima_review': 'last_review',\n",
        "    'reviews_por_mes': 'reviews_per_month',\n",
        "    'calculado_host_listings_count': 'calculated_host_listings_count',\n",
        "    'disponibilidade_365': 'availability_365'\n",
        "}\n",
        "\n",
        "rename_columns(df, mapping)"
      ],
      "metadata": {
        "id": "ojbJo_l6Twjs"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add para reposta quatro\n",
        "\n"
      ],
      "metadata": {
        "id": "93O4_JgNrhkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nova_observacao = {'id': [2595],\n",
        "                   'name': ['Skylit Midtown Castle'],\n",
        "                   'host_id': [2845],\n",
        "                   'host_name': ['Jennifer'],\n",
        "                   'neighborhood_group': ['Manhattan'],\n",
        "                   'neighborhood': ['Midtown'],\n",
        "                   'latitude': [40.75362],\n",
        "                   'longitude': [-73.98377],\n",
        "                   'room_type': ['Entire home/apt'],\n",
        "                   'price': [225],\n",
        "                   'minimum_nights': [1],\n",
        "                   'number_of_reviews': [45],\n",
        "                   'last_review': ['2019-05-21'],\n",
        "                   'reviews_per_month': [0.38],\n",
        "                   'calculated_host_listings_count': [2],\n",
        "                   'availability_365': [355]}\n",
        "\n",
        "nova_observacao_df = pd.DataFrame(nova_observacao)\n",
        "\n",
        "df = pd.concat([df, nova_observacao_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "LFlPLZmoV-hw"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratando campos nulos no campo name"
      ],
      "metadata": {
        "id": "_h1uCZYKT_o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_text(value):\n",
        "    \"\"\"\n",
        "    Pré-processa um valor de texto removendo espaços em branco adicionais e envolvendo-o em aspas simples,\n",
        "    se não for nulo.\n",
        "\n",
        "    Parâmetros:\n",
        "        value: O valor de texto a ser pré-processado.\n",
        "\n",
        "    Retorna:\n",
        "        str: O valor de texto pré-processado, com espaços em branco removidos e envolto em aspas simples,\n",
        "             se não for nulo.\n",
        "\n",
        "    Exemplo:\n",
        "        >>> preprocess_text(\"  Hello World  \")\n",
        "        \"'Hello World'\"\n",
        "    \"\"\"\n",
        "    return str(value).strip() if pd.notnull(value) else ''\n",
        "\n",
        "df['name'] = df['name'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "WsM32j1yUDOa"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removendo outliers"
      ],
      "metadata": {
        "id": "hIvqwEeIUGvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def removed_outlier(df):\n",
        "    \"\"\"\n",
        "    Remove outliers da coluna 'price' de um DataFrame.\n",
        "\n",
        "    Parâmetros:\n",
        "        df (pd.DataFrame): DataFrame contendo a coluna 'price' com os outliers a serem removidos.\n",
        "\n",
        "    Retorna:\n",
        "        pd.DataFrame: DataFrame sem os outliers na coluna 'price'.\n",
        "\n",
        "    Exemplo:\n",
        "        >>> df = pd.DataFrame({'price': [100, 150, 200, 250, 300, 1000]})\n",
        "        >>> df_sem_outliers = removed_outlier(df)\n",
        "        Número de outliers removidos: 1\n",
        "        >>> print(df_sem_outliers)\n",
        "           price\n",
        "        0    100\n",
        "        1    150\n",
        "        2    200\n",
        "        3    250\n",
        "        4    300\n",
        "    \"\"\"\n",
        "    Q1 = df['price'].quantile(0.25)\n",
        "    Q3 = df['price'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "    df_sem_outliers = df[(df['price'] >= limite_inferior) & (df['price'] <= limite_superior)]\n",
        "    print(\"Número de outliers removidos:\", len(df) - len(df_sem_outliers))\n",
        "    return df_sem_outliers\n",
        "\n",
        "df = removed_outlier(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHBLhsfPUKrR",
        "outputId": "1f56ad25-5728-4231-8b4b-579a5cd44d0a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de outliers removidos: 2972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preenchendo quantidade de review por mês"
      ],
      "metadata": {
        "id": "CN53wx09UMtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preencher_reviews_per_month(dataset):\n",
        "    \"\"\"\n",
        "    Preenche os valores faltantes na coluna 'reviews_per_month' com 0 se 'last_review' ou 'number_of_reviews' forem nulos.\n",
        "\n",
        "    Parâmetros:\n",
        "        dataset (pd.DataFrame): DataFrame contendo as colunas 'last_review', 'number_of_reviews' e 'reviews_per_month'.\n",
        "\n",
        "    Retorna:\n",
        "        pd.DataFrame: DataFrame com os valores faltantes na coluna 'reviews_per_month' preenchidos com 0.\n",
        "\n",
        "    Exemplo:\n",
        "        >>> df = pd.DataFrame({'last_review': [None, '2022-01-01', '2022-02-01', None],\n",
        "        ...                    'number_of_reviews': [10, None, 5, None],\n",
        "        ...                    'reviews_per_month': [0, 0, 0, 0]})\n",
        "        >>> df = preencher_reviews_per_month(df)\n",
        "        >>> print(df)\n",
        "           last_review  number_of_reviews  reviews_per_month\n",
        "        0         None               10.0                0.0\n",
        "        1  2022-01-01                NaN                0.0\n",
        "        2  2022-02-01                5.0                0.0\n",
        "        3         None                NaN                0.0\n",
        "    \"\"\"\n",
        "    condicao_vazios = dataset['last_review'].isnull() | dataset['number_of_reviews'].isnull()\n",
        "    dataset.loc[condicao_vazios, 'reviews_per_month'] = 0\n",
        "    return dataset\n",
        "\n",
        "# Exemplo de uso\n",
        "df = preencher_reviews_per_month(df)\n"
      ],
      "metadata": {
        "id": "FRHabEeDUSWv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adicionando total de ponto turistico por grupo de bairro"
      ],
      "metadata": {
        "id": "Nune_PV1UY2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_tourist_spot_count(dataset, tourist_spot_data):\n",
        "    \"\"\"\n",
        "    Cria o campo tourist_spot_count no dataset de locação.\n",
        "\n",
        "    Esta função calcula a quantidade de pontos turísticos em cada bairro de Nova York\n",
        "    e adiciona essa informação como uma nova coluna chamada \"tourist_spot_count\" ao\n",
        "    dataset de locação.\n",
        "\n",
        "    Parâmetros:\n",
        "    - dataset (DataFrame): O conjunto de dados de locação contendo informações sobre\n",
        "                           os imóveis em Nova York.\n",
        "    - tourist_spot_data (DataFrame): O conjunto de dados contendo informações sobre\n",
        "                                     os pontos turísticos em Nova York, com pelo menos\n",
        "                                     duas colunas: \"neighborhood\" (bairro) e\n",
        "                                     \"tourist_spot_count\" (quantidade de pontos turísticos).\n",
        "\n",
        "    Retorna:\n",
        "    - DataFrame: O dataset de locação com o campo \"tourist_spot_count\" adicionado.\n",
        "\n",
        "    Exemplo de Uso:\n",
        "    >>> dataset = add_tourist_spot_count(dataset, tourist_spot_data)\n",
        "    \"\"\"\n",
        "    borough_count = {'Bronx': 0, 'Brooklyn': 0, 'Manhattan': 0, 'Queens': 0, 'Staten Island': 0}\n",
        "\n",
        "    boroughs_of_nyc = ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island']\n",
        "\n",
        "    for address in tourist_spot_data['Address']:\n",
        "        address_lower = address.lower()\n",
        "        for borough in boroughs_of_nyc:\n",
        "            if borough.lower() in address_lower:\n",
        "                borough_count[borough] += 1\n",
        "\n",
        "    dataset['tourist_spot_count'] = 0\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "        neighborhood_group = row['neighborhood']\n",
        "        if neighborhood_group in borough_count:\n",
        "            dataset.at[index, 'tourist_spot_count'] = borough_count[neighborhood_group]\n",
        "        else:\n",
        "            # Se o bairro não estiver presente nos dados de pontos turísticos, atribua 0\n",
        "            dataset.at[index, 'tourist_spot_count'] = 0\n",
        "\n",
        "    return dataset\n",
        "\n",
        "df = add_tourist_spot_count(df, df_t)"
      ],
      "metadata": {
        "id": "dcsyYbMGUYWA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratando dos campos nulos em price"
      ],
      "metadata": {
        "id": "2VHFFR9jUg5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acomodacoes_zero = df[df['price'] == 0]\n",
        "\n",
        "for index, row in acomodacoes_zero.iterrows():\n",
        "    tipo_quarto = row['room_type']\n",
        "\n",
        "    media_tipo_quarto = df[df['room_type'] == tipo_quarto]['price'].mean()\n",
        "\n",
        "    df.at[index, 'price'] = media_tipo_quarto"
      ],
      "metadata": {
        "id": "92owpfCCUkNP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dumi de tipo de acomodação\n"
      ],
      "metadata": {
        "id": "JAWXgov1bawb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dummy_variables(df):\n",
        "    \"\"\"\n",
        "    Cria variáveis dummy para as colunas 'room_type' e 'neighborhood_group' de um DataFrame.\n",
        "\n",
        "    Parâmetros:\n",
        "        df (pd.DataFrame): DataFrame contendo as colunas 'room_type' e 'neighborhood_group' para criar variáveis dummy.\n",
        "\n",
        "    Retorna:\n",
        "        pd.DataFrame: DataFrame com variáveis dummy adicionadas para 'room_type' e 'neighborhood_group'.\n",
        "\n",
        "    Exemplo:\n",
        "        >>> df = pd.DataFrame({'room_type': ['Entire home', 'Private room', 'Shared room'],\n",
        "        ...                    'neighborhood_group': ['Bronx', 'Manhattan', 'Queens']})\n",
        "        >>> df = create_dummy_variables(df)\n",
        "        >>> print(df.columns)\n",
        "        Index(['room_type', 'neighborhood_group', 'Entire home', 'Private room', 'Shared room', 'Group A', 'Group B', 'Group C'], dtype='object')\n",
        "    \"\"\"\n",
        "    dummies_room_type = pd.get_dummies(df['room_type'])\n",
        "    df = pd.concat([df, dummies_room_type], axis=1)\n",
        "\n",
        "    dummies_neighborhood_group = pd.get_dummies(df['neighborhood_group'])\n",
        "    df = pd.concat([df, dummies_neighborhood_group], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = create_dummy_variables(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "Fyr5iBwObd1I"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "QoFixXwrWIKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_indicadores_avaliacao(y_test, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics for regression.\n",
        "\n",
        "    Parameters:\n",
        "    - y_test (array-like): True target values.\n",
        "    - y_pred (array-like): Predicted target values.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple containing SSE, SST, r_squared, and MAE.\n",
        "    \"\"\"\n",
        "    #  mean squared error (SSE)\n",
        "    SSE = mean_squared_error(y_test, y_pred) * len(y_test)\n",
        "\n",
        "    #  total sum of squares (SST)\n",
        "    SST = ((y_test - y_test.mean()) ** 2).sum()\n",
        "\n",
        "    #  R-squared\n",
        "    r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "    #  mean absolute error (MAE)\n",
        "    MAE = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    return SSE, SST, r_squared, MAE\n",
        "\n",
        "def split_y_x(df):\n",
        "    y = df['price']\n",
        "    X = df.drop(['price','name','host_id','host_name','neighborhood','neighborhood_group','room_type','last_review'],axis='columns')\n",
        "    return y,X"
      ],
      "metadata": {
        "id": "Lj3DEW47WOK3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_with_grid(df):\n",
        "    y, X = split_y_x(df)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    rf_regressor = RandomForestRegressor(n_estimators=10, max_features='sqrt', max_depth=6, min_samples_split=2, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'max_depth': [3, 4, 5, 6],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'ccp_alpha': [0.001, 0.01, 0.1, 1.0]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(rf_regressor, param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring='neg_mean_squared_error')\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_regressor = grid_search.best_estimator_\n",
        "\n",
        "    y_pred_best = best_regressor.predict(X_test)\n",
        "\n",
        "    SSE, SST, r_squared, MAE = calcular_indicadores_avaliacao(y_test, y_pred_best)\n",
        "    rmse = mean_squared_error(y_test, y_pred_best, squared=False)\n",
        "\n",
        "    # Salvar os resultados em um arquivo pickle\n",
        "    with open('random_forest_grid.pkl', 'wb') as f:\n",
        "        pickle.dump((SSE, SST, r_squared, rmse, MAE, y_pred_best), f)\n",
        "\n",
        "    return SSE, SST, r_squared, rmse, MAE, y_pred_best\n"
      ],
      "metadata": {
        "id": "1Ebw3qz6WR6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradiant"
      ],
      "metadata": {
        "id": "7naZv6QJvLDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_boosting_with_grid(df):\n",
        "    X = df.drop(['price','name','host_id','host_name','neighborhood','neighborhood_group','room_type','last_review'],axis='columns')\n",
        "    y = df['price']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.05, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5]\n",
        "    }\n",
        "\n",
        "    gb_regressor = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=gb_regressor, param_grid=param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring='r2')\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    y_pred_gb_test = best_estimator.predict(X_test)\n",
        "    r2_score_gb_test = r2_score(y_test, y_pred_gb_test)\n",
        "\n",
        "    rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb_test))\n",
        "\n",
        "    mae_gb = mean_absolute_error(y_test, y_pred_gb_test)\n",
        "\n",
        "    SSE, SST, r_squared, MAE = calcular_indicadores_avaliacao(y_test, y_pred_gb_test)\n",
        "\n",
        "    with open('gradient_boosting_grid_search_cross.pkl', 'wb') as f:\n",
        "        pickle.dump((best_params, r2_score_gb_test, rmse_gb, mae_gb, SSE, SST, r_squared, MAE, y_pred_gb_test, grid_search), f)\n",
        "\n",
        "    return best_params, r2_score_gb_test, rmse_gb, mae_gb, SSE, SST, r_squared, MAE, y_pred_gb_test, grid_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-5n6OPIvP7G",
        "outputId": "ee25e22f-05ea-44fa-ae10-fba7f2680a01"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
            "R2 Score (teste):  0.5778584570772121\n",
            "RMSE:  43.88060073604842\n",
            "MAE:  31.4856596353249\n",
            "SSE: 17685782.90598539, QME: 385.11819580570494\n",
            "SST: 41895386.044060156, QMT: 912.2963666149893\n",
            "R-quadrado: 0.5778584570772121\n",
            "MAE: 31.4856596353249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "UL4nMDtfYXsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base_model_predictions(df):\n",
        "    y, X = split_y_x(df)\n",
        "\n",
        "    # Dividir os dados em treinamento e teste\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    y_pred_rf = None\n",
        "    y_pred_gb = None\n",
        "\n",
        "    if os.path.exists('random_forest_grid.pkl'):\n",
        "        with open('random_forest_grid.pkl', 'rb') as f:\n",
        "            _, _, _, _, _, y_pred_rf = pickle.load(f)\n",
        "\n",
        "    if os.path.exists('gradient_boosting_grid_search_cross.pkl'):\n",
        "        with open('gradient_boosting_grid_search_cross.pkl', 'rb') as f:\n",
        "           best_params, r2_score_gb_test, rmse_gb, mae_gb, SSE, SST, r_squared, MAE, y_pred_gb_test, grid_search = pickle.load(f)\n",
        "\n",
        "    return y_pred_rf, y_pred_gb_test, X_test, y_test\n",
        "\n",
        "\n",
        "def train_or_load_meta_model(y_pred_rf, y_pred_gb, y_test):\n",
        "\n",
        "    X_meta = np.column_stack((y_pred_rf, y_pred_gb))\n",
        "\n",
        "    meta_regressor = GradientBoostingRegressor(random_state=42)\n",
        "    meta_regressor.fit(X_meta, y_test)\n",
        "\n",
        "    # Salvar o modelo Gradient Boosting em um arquivo\n",
        "    with open('gradient_boosting_model_combinado_random.pkl', 'wb') as f:\n",
        "        pickle.dump(meta_regressor, f)\n",
        "\n",
        "    return meta_regressor\n",
        "\n",
        "def predict_with_ensemble(meta_regressor, y_pred_rf, y_pred_gb):\n",
        "    X_meta = np.column_stack((y_pred_rf, y_pred_gb))\n",
        "    y_pred_ensemble = meta_regressor.predict(X_meta)\n",
        "\n",
        "    with open('meta_regressor_predict.pkl', 'wb') as f:\n",
        "        pickle.dump(y_pred_ensemble, f)\n",
        "\n",
        "    return y_pred_ensemble\n",
        "\n",
        "def evaluate_ensemble(y_test, y_pred_ensemble):\n",
        "    rmse_ensemble = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))\n",
        "    mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
        "    r2_score_ensemble = r2_score(y_test, y_pred_ensemble)\n",
        "\n",
        "    print(\"RMSE Ensemble: \", rmse_ensemble)\n",
        "    print(\"MAE Ensemble: \", mae_ensemble)\n",
        "    print(\"R² Score Ensemble: \", r2_score_ensemble)\n",
        "\n",
        "y_pred_rf, y_pred_gb, X_test, y_test = get_base_model_predictions(df)\n",
        "meta_regressor = train_or_load_meta_model(y_pred_rf, y_pred_gb, y_test)\n",
        "y_pred_ensemble = predict_with_ensemble(meta_regressor, y_pred_rf, y_pred_gb)\n",
        "evaluate_ensemble(y_test, y_pred_ensemble)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvfKwdCyE2wX",
        "outputId": "5270c71c-7b19-468f-9c34-f21511212482"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE Ensemble:  42.59307291966593\n",
            "MAE Ensemble:  30.606371764953895\n",
            "R² Score Ensemble:  0.6022676541666769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('meta_regressor_predict.pkl', 'rb') as f:\n",
        "    y_pred_ensemble = pickle.load(f)\n",
        "\n",
        "observacao_2595_index = df[df['id'] == 2595].index[0]\n",
        "previsao_2595_ensemble = y_pred_ensemble[observacao_2595_index]\n",
        "\n",
        "print(\"Previsão para a observação com ID 2595 pelo modelo de ensemble:\", previsao_2595_ensemble)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFVcVriCc6kB",
        "outputId": "72ded03f-a8a5-4bcf-ecf3-801b0d8dadc0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previsão para a observação com ID 2595 pelo modelo de ensemble: 180.56829960997138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pergunta 3\n",
        "\n",
        " Explique como você faria a previsão do preço a partir dos dados. Quais\n",
        "variáveis e/ou suas transformações você utilizou e por quê? Qual tipo de\n",
        "problema estamos resolvendo (regressão, classificação)? Qual modelo\n",
        "melhor se aproxima dos dados e quais seus prós e contras? Qual medida de\n",
        "performance do modelo foi escolhida e por quê?"
      ],
      "metadata": {
        "id": "fNMZONy3gWYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para prever o preço a partir dos dados em questão, foi inicialmente implementado o procedimento 'dummy' nas variáveis `neighborhood_group` e `room_type`. Esta implementação possibilitou a conversão dessas variáveis categóricas em numéricas. Ademais, criou-se uma variável chamada `tourist_spot_count` com o objetivo de quantificar os pontos turísticos em cada `neighborhood_group`. Esta variável foi obtida através da soma dos pontos turísticos pertencentes a cada `neighborhood_group` em um conjunto de dados adicional. Adicionalmente, outliers foram removidos e normalizamos dados de preços que estavam com valor zero. Isso porque se uma acomodação está cadastrada em um site de aluguel, é pouco provável que seja gratuita. Portanto, normalizamos o valor para a média do tipo de acomodação.\n",
        "\n",
        "Enquadramos o problema como uma questão de regressão, dado que a variável 'price' é uma variável quantitativa contínua. Para facilitar essa abordagem, as variáveis categóricas foram removidas.\n",
        "\n",
        "O Modelo de Regressão Ensemble apresentou a melhor performance nos testes, sendo o mais adequado para se aproximar dos dados. Este modelo é uma combinação de dois modelos distintos: Random Forest e Gradient Boosting. Cada um destes modelos foi treinado individualmente e, posteriormente, foram combinados por meio de um meta-modelo, o Gradient Boosting Regressor.\n",
        "\n",
        "A performance do modelo foi avaliada através do RMSE (Root Mean Square Error), MAE (Mean Absolute Error) e R² (R-squared). Estas métricas foram escolhidas devido à sua capacidade de fornecer uma avaliação abrangente do desempenho do modelo de regressão. O RMSE e o MAE medem a precisão das previsões em termos de erros absolutos, enquanto que o R² indica o quanto o modelo é capaz de explicar a variabilidade dos dados. A combinação destes indicadores permite uma avaliação holística do desempenho do modelo de regressão.\n",
        "\n",
        "Os resultados finais do modelo de regressão ensemble foram:\n",
        "\n",
        "- RMSE Ensemble: 42.593\n",
        "- MAE Ensemble: 30.606\n",
        "- R² Score Ensemble: 0.602"
      ],
      "metadata": {
        "id": "Q_spTh0ngkBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pergunta 4\n",
        "\n",
        "Supondo um apartamento com as seguintes características:\n",
        "\n",
        "{'id': 2595,\n",
        "'nome': 'Skylit Midtown Castle',\n",
        "'host_id': 2845,\n",
        "'host_name': 'Jennifer',\n",
        "'bairro_group': 'Manhattan',\n",
        "'bairro': 'Midtown',\n",
        "'latitude': 40.75362,\n",
        "'longitude': -73.98377,\n",
        "'room_type': 'Entire home/apt',\n",
        "'price': 225,\n",
        "'minimo_noites': 1,\n",
        "'numero_de_reviews': 45,\n",
        "'ultima_review': '2019-05-21',\n",
        "'reviews_por_mes': 0.38,\n",
        "'calculado_host_listings_count': 2,\n",
        "'disponibilidade_365': 355}"
      ],
      "metadata": {
        "id": "kvoA8I1EouQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Assim, a previsão para a observação com ID 2595 pelo nosso modelo de regressão ensemble foi de $180.57."
      ],
      "metadata": {
        "id": "qDvGmgnGo5_Y"
      }
    }
  ]
}